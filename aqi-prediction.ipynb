{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.161593Z",
     "iopub.status.busy": "2025-02-24T15:49:15.161269Z",
     "iopub.status.idle": "2025-02-24T15:49:15.462763Z",
     "shell.execute_reply": "2025-02-24T15:49:15.462051Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.161571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"WANDB_API_KEY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.464017Z",
     "iopub.status.busy": "2025-02-24T15:49:15.463737Z",
     "iopub.status.idle": "2025-02-24T15:49:15.471246Z",
     "shell.execute_reply": "2025-02-24T15:49:15.470319Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.463991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.473060Z",
     "iopub.status.busy": "2025-02-24T15:49:15.472827Z",
     "iopub.status.idle": "2025-02-24T15:49:15.482589Z",
     "shell.execute_reply": "2025-02-24T15:49:15.481752Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.473042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.483868Z",
     "iopub.status.busy": "2025-02-24T15:49:15.483664Z",
     "iopub.status.idle": "2025-02-24T15:49:15.495615Z",
     "shell.execute_reply": "2025-02-24T15:49:15.494865Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.483850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.496408Z",
     "iopub.status.busy": "2025-02-24T15:49:15.496236Z",
     "iopub.status.idle": "2025-02-24T15:49:15.505023Z",
     "shell.execute_reply": "2025-02-24T15:49:15.504339Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.496392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 71 # for reproducibility\n",
    "EXTRA_LAYER = False # for adding layer to pre-built models\n",
    "BATCH_SIZE = 80 # number of samples processed in one training batch\n",
    "EPOCHS = 50 # number of training iterations over the entire dataset\n",
    "LEARNING_RATE = 1e-2 # to update model weights\n",
    "IMG_SIZE = 224 # input image\n",
    "NUM_FROZEN_LAYERS = 0 # 0 indicates that all layers are trainable\n",
    "DROPOUT = 0.5\n",
    "\n",
    "SATELLITE_ENCODER = 'resnet18'\n",
    "STREET_ENCODER = 'resnet50'\n",
    "RUN_NAME = 'sv_resnet50_st_resnet18'\n",
    "TAGS = ['Street_resnet50', 'Satellite_resnet18']\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.506148Z",
     "iopub.status.busy": "2025-02-24T15:49:15.505861Z",
     "iopub.status.idle": "2025-02-24T15:49:15.530393Z",
     "shell.execute_reply": "2025-02-24T15:49:15.529627Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.506122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"AQI$MoleculeDetection\",\n",
    "    name=RUN_NAME,\n",
    "    tags=TAGS,\n",
    "    resume='allow',\n",
    "    allow_val_change=True,\n",
    "    config={\n",
    "        \"SEED\": SEED,\n",
    "        \"EXTRA_LAYER\": EXTRA_LAYER,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"EPOCHS\": EPOCHS,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,\n",
    "        \"IMG_SIZE\": IMG_SIZE,\n",
    "        \"NUM_FROZEN_LAYERS\": NUM_FROZEN_LAYERS,\n",
    "        \"DROPOUT\": DROPOUT,\n",
    "        \"DEVICE\": str(device),\n",
    "        \"SATELLITE_ENCODER\": SATELLITE_ENCODER,\n",
    "        \"STREET_ENCODER\": STREET_ENCODER,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "- Loads dataset: https://www.kaggle.com/datasets/adarshrouniyar/air-pollution-image-dataset-from-india-and-nepal\n",
    "- CSV consists of places and AQI measures\n",
    "- We have added an additional field for sattelite image path which was collected separately using Google earth engine.\n",
    "- Fields: Location, Filename (the street view image), Normalized_Filename (satellite image), Year, Month, Day, Hour, AQI, PM2.5, PM10, O3, CO, SO2, NO2, and AQI_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.531602Z",
     "iopub.status.busy": "2025-02-24T15:49:15.531319Z",
     "iopub.status.idle": "2025-02-24T15:49:15.595140Z",
     "shell.execute_reply": "2025-02-24T15:49:15.594449Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.531576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/aqi-dataset/dataset'\n",
    "train_csv = pd.read_csv(os.path.join(dataset_path, 'train_data.csv'))\n",
    "val_csv = pd.read_csv(os.path.join(dataset_path, 'val_data.csv'))\n",
    "test_csv = pd.read_csv(os.path.join(dataset_path, 'test_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Initialization (`__init__`)**  \n",
    "   - Takes a **CSV file** (*pandas DataFrame*) containing **filenames and labels**.  \n",
    "   - **`satellite_img_dir`** & **`street_img_dir`**: Directories where **satellite** and **street images** are stored.  \n",
    "   - **`label`**: Column name in the CSV corresponding to the **target label**.  \n",
    "   - **`satellite_transform`** & **`street_transform`**: Optional transformations (e.g., **resizing, normalization**) for images.  \n",
    "\n",
    "#### **2. Dataset Length (`__len__`)**  \n",
    "   - Returns the **total number of samples** (rows) in the CSV file.  \n",
    "\n",
    "#### **3. Get Item (`__getitem__`)**  \n",
    "   - Retrieves the **street image** and **satellite image** paths from the CSV.  \n",
    "   - Loads the images using the **`load_image()`** method.  \n",
    "   - Applies the **respective transformations** if provided.  \n",
    "   - Converts the **label** to a **PyTorch tensor** of type `float32`.  \n",
    "   - Returns a tuple: **`(street_image, satellite_image, label)`**.  \n",
    "\n",
    "#### **4. Image Loading (`load_image`)**  \n",
    "   - Opens an image using **PIL** (`Image.open(file_path)`).  \n",
    "   - Applies **transformations** if specified.  \n",
    "   - Returns the **processed image**. ðŸš€  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.597377Z",
     "iopub.status.busy": "2025-02-24T15:49:15.597182Z",
     "iopub.status.idle": "2025-02-24T15:49:15.604134Z",
     "shell.execute_reply": "2025-02-24T15:49:15.603274Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.597360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, satellite_img_dir, street_img_dir, label, satellite_transform=None, street_transform=None):\n",
    "        self.data = csv_file\n",
    "        self.street_img_dir = street_img_dir\n",
    "        self.satellite_img_dir = satellite_img_dir\n",
    "        self.label = label\n",
    "        self.satellite_transform = satellite_transform\n",
    "        self.street_transform = street_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        street_image_path = os.path.join(self.street_img_dir, self.data['Filename'].iloc[idx])\n",
    "        satellite_image_path = os.path.join(self.satellite_img_dir, self.data['Normalized_Filename'].iloc[idx]+'.npy' )\n",
    "        \n",
    "        street_image = self.load_image(street_image_path, self.street_transform)\n",
    "        # satellite_image = self.load_image(satellite_image_path, self.satellite_transform)\n",
    "        satellite_image = self.load_npy(satellite_image_path, self.satellite_transform)\n",
    "        label = torch.tensor(self.data[self.label].iloc[idx], dtype=torch.float32)\n",
    "        \n",
    "        return street_image, satellite_image, label\n",
    "        \n",
    "    \n",
    "    def load_image(self, file_path, transform=None):\n",
    "        img = Image.open(file_path)\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        return img\n",
    "    \n",
    "    def load_npy(self, file_path, transform=None):\n",
    "        img = np.load(file_path)\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization and tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.605994Z",
     "iopub.status.busy": "2025-02-24T15:49:15.605667Z",
     "iopub.status.idle": "2025-02-24T15:49:15.618681Z",
     "shell.execute_reply": "2025-02-24T15:49:15.617950Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.605973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for nomalization\n",
    "image_net_means = [0.485, 0.456, 0.406] \n",
    "image_net_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "satellite_net_means = [0.18168019890450375, 0.18805927958530722, 0.20592676343591497, 0.20806291225568016, 0.3423790143310607, 0.23654847637549638, 0.17482840221654344]\n",
    "\n",
    "satellite_net_stds = [0.19048610465575523, 0.19615030016268702, 0.2125846014779801,  0.21476670175116374, 0.347457205638518, 0.2390436189214837, 0.17736793155031446]\n",
    "# for data transformation\n",
    "data_transforms = {\n",
    "    'street_dev': transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n",
    "        transforms.Normalize(tuple(image_net_means), tuple(image_net_stds))\n",
    "    ]),\n",
    "    'street_test': transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n",
    "        transforms.Normalize(tuple(image_net_means), tuple(image_net_stds))\n",
    "    ]),\n",
    "    'satellite_dev': transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n",
    "        transforms.Normalize(tuple(satellite_net_means), tuple(satellite_net_stds))\n",
    "    ]),\n",
    "    'satellite_test': transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n",
    "        transforms.Normalize(tuple(satellite_net_means), tuple(satellite_net_stds))\n",
    "    ])\n",
    "}   \n",
    "    \n",
    "# image specific tranformations    \n",
    "satellite_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Normalize(tuple(satellite_net_means), tuple(satellite_net_stds)),\n",
    "])\n",
    "\n",
    "street_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.Normalize(tuple(image_net_means), tuple(image_net_stds)),\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders \n",
    "\n",
    "1. **Creating Datasets (`CustomDataset`)**  \n",
    "   - `train_dataset`: Uses **augmented transforms** (`satellite_transform`, `street_transform`).  \n",
    "   - `val_dataset` & `test_dataset`: Use **only normalization** (`data_transforms['dev']` & `data_transforms['test']`).  \n",
    "\n",
    "2. **Data Loaders (`DataLoader`)**  \n",
    "   - `train_loader`: Loads training data with **shuffling** for randomness.  \n",
    "   - `val_loader` & `test_loader`: Load validation & test data **without shuffling** for consistency.  \n",
    "\n",
    "Usage:\n",
    "- Prepares **train, validation, and test sets** for deep learning models.  \n",
    "- Uses **batch processing (`batch_size=BATCH_SIZE`)** for efficient training.  \n",
    "- **`next(iter(train_loader))`** retrieves a single batch to inspect data. ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.619567Z",
     "iopub.status.busy": "2025-02-24T15:49:15.619384Z",
     "iopub.status.idle": "2025-02-24T15:49:15.635320Z",
     "shell.execute_reply": "2025-02-24T15:49:15.634521Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.619550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', satellite_transform, street_transform)\n",
    "\n",
    "val_dataset = CustomDataset(val_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', data_transforms['satellite_dev'], data_transforms['street_dev'])\n",
    "\n",
    "test_dataset = CustomDataset(test_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', data_transforms['satellite_test'], data_transforms['street_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.636319Z",
     "iopub.status.busy": "2025-02-24T15:49:15.636110Z",
     "iopub.status.idle": "2025-02-24T15:49:15.648402Z",
     "shell.execute_reply": "2025-02-24T15:49:15.647624Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.636290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.649482Z",
     "iopub.status.busy": "2025-02-24T15:49:15.649229Z",
     "iopub.status.idle": "2025-02-24T15:49:15.661248Z",
     "shell.execute_reply": "2025-02-24T15:49:15.660567Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.649461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.662241Z",
     "iopub.status.busy": "2025-02-24T15:49:15.661993Z",
     "iopub.status.idle": "2025-02-24T15:49:15.670023Z",
     "shell.execute_reply": "2025-02-24T15:49:15.669365Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.662222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# temp = next(iter(train_loader))\n",
    "# print(temp[0].shape, temp[1].shape, temp[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.671109Z",
     "iopub.status.busy": "2025-02-24T15:49:15.670816Z",
     "iopub.status.idle": "2025-02-24T15:49:15.682838Z",
     "shell.execute_reply": "2025-02-24T15:49:15.682155Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.671081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss_fn_regression(outputs, targets):\n",
    "    \"\"\"\n",
    "    Loss function for regression\n",
    "    \"\"\"\n",
    "    return nn.MSELoss()(outputs, targets)\n",
    "\n",
    "\n",
    "def loss_fn_classification(outputs, targets):\n",
    "    \"\"\"\n",
    "    Loss function for classification\n",
    "    \"\"\"\n",
    "\n",
    "    return nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "\n",
    "def accuracy(outputs, targets):\n",
    "    \"\"\"\n",
    "    Accuracy function\n",
    "    \"\"\"\n",
    "\n",
    "    return (outputs.argmax(1) == targets).float().mean()\n",
    "\n",
    "\n",
    "def rmse(outputs, targets):\n",
    "    \"\"\"\n",
    "    RMSE function\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))\n",
    "\n",
    "\n",
    "def mae(outputs, targets):\n",
    "    \"\"\"\n",
    "    MAE function\n",
    "    \"\"\"\n",
    "\n",
    "    return nn.L1Loss()(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing - forward pass\n",
    "Processes a batch of data through the model and computes loss & metrics.  \n",
    "\n",
    "1. **Inputs:**  \n",
    "   - `data`: (street images, satellite images, targets)  \n",
    "   - `model`: Deep learning model  \n",
    "   - `device`: CPU/GPU  \n",
    "   - `is_classification`: Flag for classification vs. regression  \n",
    "\n",
    "2. **Steps:**  \n",
    "   - Move data to **device**.  \n",
    "   - Forward pass through **model**.  \n",
    "   - Compute **loss** (classification or regression).  \n",
    "   - Compute **accuracy** (only for classification).  \n",
    "   - Compute **RMSE & MAE** (for both tasks).  \n",
    "\n",
    "3. **Outputs:**  \n",
    "   - Loss, Accuracy (0 for regression), RMSE, MAE ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.684007Z",
     "iopub.status.busy": "2025-02-24T15:49:15.683715Z",
     "iopub.status.idle": "2025-02-24T15:49:15.694614Z",
     "shell.execute_reply": "2025-02-24T15:49:15.693901Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.683980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_batch(data, model, device, is_classification):\n",
    "    \"\"\"Processes a batch and returns outputs, loss, and metrics.\"\"\"\n",
    "    street_img, satellite_img, targets = data\n",
    "    street_img, satellite_img, targets = street_img.to(device), satellite_img.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(street_img, satellite_img)\n",
    "    \n",
    "    if is_classification:\n",
    "        loss = loss_fn_classification(outputs, targets)\n",
    "        acc = accuracy(outputs, targets).item()\n",
    "    else:\n",
    "        targets = targets.unsqueeze(1)\n",
    "        loss = loss_fn_regression(outputs, targets)\n",
    "        acc = 0  # Placeholder, as accuracy isn't relevant for regression\n",
    "\n",
    "    rmse_score = rmse(outputs, targets).item()\n",
    "    mae_score = mae(outputs, targets).item()\n",
    "\n",
    "    return loss, acc, rmse_score, mae_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluation functions\n",
    "1. **`train_fn(model, optimizer, scheduler, data_loader, device, is_classification=False)`**  \n",
    "   - Trains the model for one epoch by iterating over the training dataset, computing loss, and updating weights using backpropagation.  \n",
    "   - Tracks and prints batch-wise loss, RMSE, and MAE while applying learning rate scheduling.  \n",
    "\n",
    "2. **`eval_fn(model, data_loader, device, is_classification=False)`**  \n",
    "   - Evaluates the model on validation or test data without updating weights.  \n",
    "   - Computes and returns the average loss, accuracy (if applicable), RMSE, and MAE for the entire dataset.  \n",
    "\n",
    "3. **`train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, epochs=10, best_model_path='best_model.pth')`**  \n",
    "   - Manages the full training process across multiple epochs, tracking performance on both training and validation sets.  \n",
    "   - Saves the best-performing model based on validation loss and evaluates it on the test dataset after training. ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.695453Z",
     "iopub.status.busy": "2025-02-24T15:49:15.695222Z",
     "iopub.status.idle": "2025-02-24T15:49:15.704262Z",
     "shell.execute_reply": "2025-02-24T15:49:15.703577Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.695435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, data_loader, device, is_classification=False):\n",
    "    \"\"\"Training function\"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_acc, total_rmse, total_mae = 0, 0, 0, 0\n",
    "\n",
    "    for i, data in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, acc, rmse_score, mae_score = process_batch(data, model, device, is_classification)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Aggregate metrics\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        total_rmse += rmse_score\n",
    "        total_mae += mae_score\n",
    "        \n",
    "        wandb.log({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"batch_acc\": acc,\n",
    "            \"batch_rmse\": rmse_score,\n",
    "            \"batch_mae\": mae_score\n",
    "        })\n",
    "\n",
    "        print(f\"Batch: {i+1}/{len(data_loader)}, Loss: {total_loss / (i+1):.4f}, RMSE: {total_rmse / (i+1):.4f}, MAE: {total_mae / (i+1):.4f}\", end='\\r')\n",
    "\n",
    "    print()  # Ensure proper formatting after tqdm\n",
    "\n",
    "    epoch_loss = total_loss / len(data_loader)\n",
    "    epoch_acc = total_acc / len(data_loader)\n",
    "    epoch_rmse = total_rmse / len(data_loader)\n",
    "    epoch_mae = total_mae / len(data_loader)\n",
    "\n",
    "    # Log epoch-wise metrics to WandB\n",
    "    wandb.log({\n",
    "        \"epoch_loss\": epoch_loss,\n",
    "        \"epoch_acc\": epoch_acc,\n",
    "        \"epoch_rmse\": epoch_rmse,\n",
    "        \"epoch_mae\": epoch_mae\n",
    "    })\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_rmse, epoch_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.705252Z",
     "iopub.status.busy": "2025-02-24T15:49:15.705034Z",
     "iopub.status.idle": "2025-02-24T15:49:15.720324Z",
     "shell.execute_reply": "2025-02-24T15:49:15.719517Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.705213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_fn(model, data_loader, device, is_classification=False):\n",
    "    \"\"\"Evaluation function\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_rmse, total_mae = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Evaluating\"):\n",
    "            loss, acc, rmse_score, mae_score = process_batch(data, model, device, is_classification)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            total_rmse += rmse_score\n",
    "            total_mae += mae_score\n",
    "\n",
    "    val_loss = total_loss / len(data_loader)\n",
    "    val_acc = total_acc / len(data_loader)\n",
    "    val_rmse = total_rmse / len(data_loader)\n",
    "    val_mae = total_mae / len(data_loader)\n",
    "\n",
    "    # Log validation metrics to WandB\n",
    "    wandb.log({\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_rmse\": val_rmse,\n",
    "        \"val_mae\": val_mae\n",
    "    })\n",
    "\n",
    "    return val_loss, val_acc, val_rmse, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.721312Z",
     "iopub.status.busy": "2025-02-24T15:49:15.721114Z",
     "iopub.status.idle": "2025-02-24T15:49:15.736678Z",
     "shell.execute_reply": "2025-02-24T15:49:15.735938Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.721295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, epochs=10, best_model_path='best_model.pth'):\n",
    "    \"\"\"Main training loop\"\"\"\n",
    "    model.to(device)\n",
    "    history = {\"losses\": [], \"accuracies\": [], \"rmse_scores\": [], \"mae_scores\": []}\n",
    "\n",
    "    best_loss = np.inf\n",
    "    # best_model_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        train_metrics = train_fn(model, optimizer, scheduler, train_loader, device, is_classification=False)\n",
    "        val_metrics = eval_fn(model, val_loader, device, is_classification=False)\n",
    "\n",
    "        history[\"losses\"].append((train_metrics[0], val_metrics[0]))\n",
    "        history[\"accuracies\"].append((train_metrics[1], val_metrics[1]))\n",
    "        history[\"rmse_scores\"].append((train_metrics[2], val_metrics[2]))\n",
    "        history[\"mae_scores\"].append((train_metrics[3], val_metrics[3]))\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_metrics[0]:.4f}, Train Acc: {train_metrics[1]:.4f}, Train RMSE: {train_metrics[2]:.4f}, Train MAE: {train_metrics[3]:.4f}, Val Loss: {val_metrics[0]:.4f}, Val Acc: {val_metrics[1]:.4f}, Val RMSE: {val_metrics[2]:.4f}, Val MAE: {val_metrics[3]:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics[0] < best_loss:\n",
    "            best_loss = val_metrics[0]\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            wandb.save(best_model_path) \n",
    "\n",
    "    # Load best model and evaluate on test set\n",
    "    model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "    test_metrics = eval_fn(model, test_loader, device, is_classification=False)\n",
    "    wandb.log({\n",
    "        \"test_loss\": test_metrics[0],\n",
    "        \"test_acc\": test_metrics[1],\n",
    "        \"test_rmse\": test_metrics[2],\n",
    "        \"test_mae\": test_metrics[3]\n",
    "    })\n",
    "    print(f\"Test Loss: {test_metrics[0]:.4f}, Test Acc: {test_metrics[1]:.4f}, Test RMSE: {test_metrics[2]:.4f}, Test MAE: {test_metrics[3]:.4f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.737698Z",
     "iopub.status.busy": "2025-02-24T15:49:15.737439Z",
     "iopub.status.idle": "2025-02-24T15:49:15.753990Z",
     "shell.execute_reply": "2025-02-24T15:49:15.753260Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.737673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(losses, accuracies, rmse_scores, mae_scores, model_name=\"Model Metrics\"):\n",
    "    \"\"\"\n",
    "    Plot training metrics with a title.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    fig.suptitle(model_name, fontsize=20, fontweight=\"bold\")  # Add model title\n",
    "\n",
    "    ax[0, 0].plot(losses)\n",
    "    ax[0, 0].set_title(\"Loss\")\n",
    "    ax[0, 0].legend([\"Train\", \"Val\"])\n",
    "\n",
    "    ax[0, 1].plot(accuracies)\n",
    "    ax[0, 1].set_title(\"Accuracy\")\n",
    "    ax[0, 1].legend([\"Train\", \"Val\"])\n",
    "\n",
    "    ax[1, 0].plot(rmse_scores)\n",
    "    ax[1, 0].set_title(\"RMSE\")\n",
    "    ax[1, 0].legend([\"Train\", \"Val\"])\n",
    "\n",
    "    ax[1, 1].plot(mae_scores)\n",
    "    ax[1, 1].set_title(\"MAE\")\n",
    "    ax[1, 1].legend([\"Train\", \"Val\"])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "1. Initializes base based on architecture selected.\n",
    "2. Removes classification layer\n",
    "3. Adjusts first layer based on number of channels\n",
    "4. Adds final layers to extract features of image\n",
    "5. Freeze layers depending on number of layers\n",
    "6. Combine everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.754970Z",
     "iopub.status.busy": "2025-02-24T15:49:15.754751Z",
     "iopub.status.idle": "2025-02-24T15:49:15.768536Z",
     "shell.execute_reply": "2025-02-24T15:49:15.767809Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.754952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A flexible encoder model that supports different architectures (ResNet, EfficientNet, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, arch=\"resnet18\", pretrained=True, no_channels=3, dropout=0.5, add_block=False, num_frozen=0):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.num_frozen = num_frozen\n",
    "\n",
    "        # Dictionary of available architectures\n",
    "        arch_dict = {\n",
    "            \"resnet18\": models.resnet18,\n",
    "            \"resnet50\": models.resnet50,\n",
    "            \"resnet101\": models.resnet101,\n",
    "            \"efficientnet_b0\": models.efficientnet_b0,\n",
    "            \"efficientnet_b4\": models.efficientnet_b4,\n",
    "        }\n",
    "\n",
    "        assert arch in arch_dict, f\"Unsupported architecture: {arch}. Choose from {list(arch_dict.keys())}\"\n",
    "\n",
    "        # Load the model\n",
    "        self.model = arch_dict[arch](weights=\"DEFAULT\" if pretrained else None)\n",
    "\n",
    "        if \"resnet\" in arch:\n",
    "            self.feature_dim = self.model.fc.in_features\n",
    "            self.model.fc = nn.Identity()  \n",
    "        elif \"efficientnet\" in arch:\n",
    "            self.feature_dim = self.model.classifier[1].in_features\n",
    "            self.model.classifier = nn.Identity() \n",
    "\n",
    "        if no_channels != 3:\n",
    "            if \"resnet\" in arch:\n",
    "                self.model.conv1 = nn.Conv2d(no_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            elif \"efficientnet\" in arch:\n",
    "                self.model.features[0][0] = nn.Conv2d(no_channels, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "\n",
    "\n",
    "        if self.add_block:\n",
    "            self.addition_block = nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, self.feature_dim),\n",
    "                nn.BatchNorm1d(self.feature_dim),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(self.feature_dim, self.feature_dim)\n",
    "            )\n",
    "\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 512)\n",
    "        )\n",
    "\n",
    "        self.freeze_layers()\n",
    "\n",
    "    def freeze_layers(self):\n",
    "        \"\"\"\n",
    "        Freeze the first `num_frozen` layers of the model.\n",
    "        \"\"\"\n",
    "        layers = list(self.model.children())\n",
    "        assert 0 <= self.num_frozen <= len(layers), \\\n",
    "            f\"num_frozen should be between 0 and {len(layers)}\"\n",
    "\n",
    "        for i, child in enumerate(layers):\n",
    "            if i < self.num_frozen:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        print(f\"Number of frozen layers: {self.num_frozen}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        if self.add_block:\n",
    "            x = self.addition_block(x)\n",
    "        x = self.final_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQI model\n",
    "1. Concats output from 2 models: 1 for satellite features, 1 for street image features\n",
    "2. Adds final layers (depending on classification, regression)\n",
    "3. Forming a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.769772Z",
     "iopub.status.busy": "2025-02-24T15:49:15.769501Z",
     "iopub.status.idle": "2025-02-24T15:49:15.781638Z",
     "shell.execute_reply": "2025-02-24T15:49:15.781034Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.769742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AQIPrediction(nn.Module):\n",
    "    \"\"\"\n",
    "    Unified model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, satellite_model, street_model, dropout=0.5, num_classes=None):\n",
    "        \n",
    "        super(AQIPrediction, self).__init__()\n",
    "        \n",
    "        self.satellite_model = satellite_model\n",
    "        self.street_model = street_model\n",
    "        \n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(512 + 512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        if num_classes:\n",
    "            self.final_layers[-1] = nn.Linear(128, num_classes)\n",
    "            \n",
    "    def forward(self, street_img, satellite_img):\n",
    "        \n",
    "        street_features = self.street_model(street_img)\n",
    "        satellite_features = self.satellite_model(satellite_img)\n",
    "        \n",
    "        features = torch.cat((street_features, satellite_features), dim=1)\n",
    "        output = self.final_layers(features)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Creating the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:49:15.782564Z",
     "iopub.status.busy": "2025-02-24T15:49:15.782319Z",
     "iopub.status.idle": "2025-02-24T15:55:04.404997Z",
     "shell.execute_reply": "2025-02-24T15:55:04.400739Z",
     "shell.execute_reply.started": "2025-02-24T15:49:15.782535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "satellite_encoder = BaseEncoder(arch=SATELLITE_ENCODER, no_channels=3, dropout=DROPOUT, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n",
    "street_encoder = BaseEncoder(arch=STREET_ENCODER, no_channels=3, dropout=DROPOUT, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n",
    "\n",
    "model = AQIPrediction(satellite_encoder, street_encoder, dropout=DROPOUT, num_classes=None)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "history = train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, EPOCHS, f'{RUN_NAME}_best_model.pth')\n",
    "\n",
    "plot_metrics(**history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T15:55:04.407851Z",
     "iopub.status.busy": "2025-02-24T15:55:04.407530Z",
     "iopub.status.idle": "2025-02-24T15:55:04.411917Z",
     "shell.execute_reply": "2025-02-24T15:55:04.411295Z",
     "shell.execute_reply.started": "2025-02-24T15:55:04.407826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# np.random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# satellite_encoder = BaseEncoder(arch='resnet50', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n",
    "# street_encoder = BaseEncoder(arch='resnet50', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n",
    "\n",
    "# model = AQIPrediction(satellite_encoder, street_encoder, dropout=0.5, num_classes=None)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "# history = train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, EPOCHS, 'resnet50_best_model.pth')\n",
    "\n",
    "# plot_metrics(**history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6574811,
     "sourceId": 10857041,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
