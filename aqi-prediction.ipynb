{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10619044,"sourceType":"datasetVersion","datasetId":6574811}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom time import time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:20.183761Z","iopub.execute_input":"2025-02-08T15:52:20.184123Z","iopub.status.idle":"2025-02-08T15:52:20.630165Z","shell.execute_reply.started":"2025-02-08T15:52:20.184076Z","shell.execute_reply":"2025-02-08T15:52:20.629315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:20.631315Z","iopub.execute_input":"2025-02-08T15:52:20.631654Z","iopub.status.idle":"2025-02-08T15:52:26.045556Z","shell.execute_reply.started":"2025-02-08T15:52:20.631633Z","shell.execute_reply":"2025-02-08T15:52:26.044667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 71\nEXTRA_LAYER = True\nBATCH_SIZE = 80\nEPOCHS = 30\nLEARNING_RATE = 1e-2\nIMG_SIZE = 224\nNUM_FROZEN_LAYERS = 0\n\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.047410Z","iopub.execute_input":"2025-02-08T15:52:26.048059Z","iopub.status.idle":"2025-02-08T15:52:26.100431Z","shell.execute_reply.started":"2025-02-08T15:52:26.047996Z","shell.execute_reply":"2025-02-08T15:52:26.099407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = '/kaggle/input/aqi-dataset/dataset'\ntrain_csv = pd.read_csv(os.path.join(dataset_path, 'train_data.csv'))\nval_csv = pd.read_csv(os.path.join(dataset_path, 'val_data.csv'))\ntest_csv = pd.read_csv(os.path.join(dataset_path, 'test_data.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.101859Z","iopub.execute_input":"2025-02-08T15:52:26.102201Z","iopub.status.idle":"2025-02-08T15:52:26.196265Z","shell.execute_reply.started":"2025-02-08T15:52:26.102175Z","shell.execute_reply":"2025-02-08T15:52:26.195545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, csv_file, satellite_img_dir, street_img_dir, label, satellite_transform=None, street_transform=None):\n        self.data = csv_file\n        self.street_img_dir = street_img_dir\n        self.satellite_img_dir = satellite_img_dir\n        self.label = label\n        self.satellite_transform = satellite_transform\n        self.street_transform = street_transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        street_image_path = os.path.join(self.street_img_dir, self.data['Filename'].iloc[idx])\n        satellite_image_path = os.path.join(self.satellite_img_dir, self.data['Normalized_Filename'].iloc[idx]+'.jpg' )\n        \n        street_image = self.load_image(street_image_path, self.street_transform)\n        satellite_image = self.load_image(satellite_image_path, self.satellite_transform)\n        label = torch.tensor(self.data[self.label].iloc[idx], dtype=torch.float32)\n        \n        return street_image, satellite_image, label\n        \n    \n    def load_image(self, file_path, transform=None):\n        img = Image.open(file_path)\n        if transform:\n            img = transform(img)\n        return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.196920Z","iopub.execute_input":"2025-02-08T15:52:26.197182Z","iopub.status.idle":"2025-02-08T15:52:26.203484Z","shell.execute_reply.started":"2025-02-08T15:52:26.197162Z","shell.execute_reply":"2025-02-08T15:52:26.202521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_net_means = [0.485, 0.456, 0.406]\nimage_net_stds = [0.229, 0.224, 0.225]\n\ndata_transforms = {\n    'dev': transforms.Compose([\n        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n        transforms.Normalize(tuple(image_net_means), tuple(image_net_stds))\n    ]),\n    'test': transforms.Compose([\n        transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)\n        transforms.Normalize(tuple(image_net_means), tuple(image_net_stds))\n    ])\n}   \n    \n    \nsatellite_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(),  \n    transforms.RandomVerticalFlip(),\n    transforms.Normalize(tuple(image_net_means), tuple(image_net_stds))\n])\n\nstreet_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(), \n    transforms.Normalize(tuple(image_net_means), tuple(image_net_stds)),\n])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.204344Z","iopub.execute_input":"2025-02-08T15:52:26.204562Z","iopub.status.idle":"2025-02-08T15:52:26.219176Z","shell.execute_reply.started":"2025-02-08T15:52:26.204544Z","shell.execute_reply":"2025-02-08T15:52:26.218398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CustomDataset(train_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', satellite_transform, street_transform)\n\nval_dataset = CustomDataset(val_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', data_transforms['dev'], data_transforms['dev'])\n\ntest_dataset = CustomDataset(test_csv, os.path.join(dataset_path, 'satellite_images'), os.path.join(dataset_path, 'All_img'), 'AQI', data_transforms['test'], data_transforms['test'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.220057Z","iopub.execute_input":"2025-02-08T15:52:26.220326Z","iopub.status.idle":"2025-02-08T15:52:26.235289Z","shell.execute_reply.started":"2025-02-08T15:52:26.220297Z","shell.execute_reply":"2025-02-08T15:52:26.234537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n# data = next(iter(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.236140Z","iopub.execute_input":"2025-02-08T15:52:26.236343Z","iopub.status.idle":"2025-02-08T15:52:26.248512Z","shell.execute_reply.started":"2025-02-08T15:52:26.236325Z","shell.execute_reply":"2025-02-08T15:52:26.247800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_loader), len(val_loader), len(test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.250656Z","iopub.execute_input":"2025-02-08T15:52:26.250844Z","iopub.status.idle":"2025-02-08T15:52:26.264375Z","shell.execute_reply.started":"2025-02-08T15:52:26.250828Z","shell.execute_reply":"2025-02-08T15:52:26.263672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# temp = next(iter(train_loader))\n# print(temp[0].shape, temp[1].shape, temp[2].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.265375Z","iopub.execute_input":"2025-02-08T15:52:26.265639Z","iopub.status.idle":"2025-02-08T15:52:26.278193Z","shell.execute_reply.started":"2025-02-08T15:52:26.265614Z","shell.execute_reply":"2025-02-08T15:52:26.277346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def loss_fn_regression(outputs, targets):\n    \"\"\"\n    Loss function for regression\n    \"\"\"\n    return nn.MSELoss()(outputs, targets)\n\n\ndef loss_fn_classification(outputs, targets):\n    \"\"\"\n    Loss function for classification\n    \"\"\"\n\n    return nn.CrossEntropyLoss()(outputs, targets)\n\n\ndef accuracy(outputs, targets):\n    \"\"\"\n    Accuracy function\n    \"\"\"\n\n    return (outputs.argmax(1) == targets).float().mean()\n\n\ndef rmse(outputs, targets):\n    \"\"\"\n    RMSE function\n    \"\"\"\n\n    return torch.sqrt(nn.MSELoss()(outputs, targets))\n\n\ndef mae(outputs, targets):\n    \"\"\"\n    MAE function\n    \"\"\"\n\n    return nn.L1Loss()(outputs, targets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.278975Z","iopub.execute_input":"2025-02-08T15:52:26.279198Z","iopub.status.idle":"2025-02-08T15:52:26.289798Z","shell.execute_reply.started":"2025-02-08T15:52:26.279175Z","shell.execute_reply":"2025-02-08T15:52:26.289078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_batch(data, model, device, is_classification):\n    \"\"\"Processes a batch and returns outputs, loss, and metrics.\"\"\"\n    street_img, satellite_img, targets = data\n    street_img, satellite_img, targets = street_img.to(device), satellite_img.to(device), targets.to(device)\n    \n    outputs = model(street_img, satellite_img)\n    \n    if is_classification:\n        loss = loss_fn_classification(outputs, targets)\n        acc = accuracy(outputs, targets).item()\n    else:\n        targets = targets.unsqueeze(1)\n        loss = loss_fn_regression(outputs, targets)\n        acc = 0  # Placeholder, as accuracy isn't relevant for regression\n\n    rmse_score = rmse(outputs, targets).item()\n    mae_score = mae(outputs, targets).item()\n\n    return loss, acc, rmse_score, mae_score\n\ndef train_fn(model, optimizer, scheduler, data_loader, device, is_classification=False):\n    \"\"\"Training function\"\"\"\n    model.train()\n    total_loss, total_acc, total_rmse, total_mae = 0, 0, 0, 0\n\n    for i, data in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Training\"):\n        optimizer.zero_grad()\n\n        loss, acc, rmse_score, mae_score = process_batch(data, model, device, is_classification)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # Aggregate metrics\n        total_loss += loss.item()\n        total_acc += acc\n        total_rmse += rmse_score\n        total_mae += mae_score\n\n        print(f\"Batch: {i+1}/{len(data_loader)}, Loss: {total_loss / (i+1):.4f}, RMSE: {total_rmse / (i+1):.4f}, MAE: {total_mae / (i+1):.4f}\", end='\\r')\n\n    print()  # Ensure proper formatting after tqdm\n    return total_loss / len(data_loader), total_acc / len(data_loader), total_rmse / len(data_loader), total_mae / len(data_loader)\n\ndef eval_fn(model, data_loader, device, is_classification=False):\n    \"\"\"Evaluation function\"\"\"\n    model.eval()\n    total_loss, total_acc, total_rmse, total_mae = 0, 0, 0, 0\n\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Evaluating\"):\n            loss, acc, rmse_score, mae_score = process_batch(data, model, device, is_classification)\n\n            total_loss += loss.item()\n            total_acc += acc\n            total_rmse += rmse_score\n            total_mae += mae_score\n\n    return total_loss / len(data_loader), total_acc / len(data_loader), total_rmse / len(data_loader), total_mae / len(data_loader)\n\ndef train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, epochs=10, best_model_path='best_model.pth'):\n    \"\"\"Main training loop\"\"\"\n    model.to(device)\n    history = {\"losses\": [], \"accuracies\": [], \"rmse_scores\": [], \"mae_scores\": []}\n\n    best_loss = np.inf\n    # best_model_path = \"best_model.pth\"\n\n    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n        train_metrics = train_fn(model, optimizer, scheduler, train_loader, device, is_classification=False)\n        val_metrics = eval_fn(model, val_loader, device, is_classification=False)\n\n        history[\"losses\"].append((train_metrics[0], val_metrics[0]))\n        history[\"accuracies\"].append((train_metrics[1], val_metrics[1]))\n        history[\"rmse_scores\"].append((train_metrics[2], val_metrics[2]))\n        history[\"mae_scores\"].append((train_metrics[3], val_metrics[3]))\n\n        print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_metrics[0]:.4f}, Train Acc: {train_metrics[1]:.4f}, Train RMSE: {train_metrics[2]:.4f}, Train MAE: {train_metrics[3]:.4f}, Val Loss: {val_metrics[0]:.4f}, Val Acc: {val_metrics[1]:.4f}, Val RMSE: {val_metrics[2]:.4f}, Val MAE: {val_metrics[3]:.4f}\")\n\n        # Save best model\n        if val_metrics[0] < best_loss:\n            best_loss = val_metrics[0]\n            torch.save(model.state_dict(), best_model_path)\n\n    # Load best model and evaluate on test set\n    model.load_state_dict(torch.load(best_model_path, weights_only=True))\n    test_metrics = eval_fn(model, test_loader, device, is_classification=False)\n    print(f\"Test Loss: {test_metrics[0]:.4f}, Test Acc: {test_metrics[1]:.4f}, Test RMSE: {test_metrics[2]:.4f}, Test MAE: {test_metrics[3]:.4f}\")\n\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.290671Z","iopub.execute_input":"2025-02-08T15:52:26.290944Z","iopub.status.idle":"2025-02-08T15:52:26.440446Z","shell.execute_reply.started":"2025-02-08T15:52:26.290917Z","shell.execute_reply":"2025-02-08T15:52:26.439483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_metrics(losses, accuracies, rmse_scores, mae_scores, model_name=\"Model Metrics\"):\n    \"\"\"\n    Plot training metrics with a title.\n    \"\"\"\n\n    fig, ax = plt.subplots(2, 2, figsize=(20, 15))\n    fig.suptitle(model_name, fontsize=20, fontweight=\"bold\")  # Add model title\n\n    ax[0, 0].plot(losses)\n    ax[0, 0].set_title(\"Loss\")\n    ax[0, 0].legend([\"Train\", \"Val\"])\n\n    ax[0, 1].plot(accuracies)\n    ax[0, 1].set_title(\"Accuracy\")\n    ax[0, 1].legend([\"Train\", \"Val\"])\n\n    ax[1, 0].plot(rmse_scores)\n    ax[1, 0].set_title(\"RMSE\")\n    ax[1, 0].legend([\"Train\", \"Val\"])\n\n    ax[1, 1].plot(mae_scores)\n    ax[1, 1].set_title(\"MAE\")\n    ax[1, 1].legend([\"Train\", \"Val\"])\n\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.441316Z","iopub.execute_input":"2025-02-08T15:52:26.441624Z","iopub.status.idle":"2025-02-08T15:52:26.456084Z","shell.execute_reply.started":"2025-02-08T15:52:26.441593Z","shell.execute_reply":"2025-02-08T15:52:26.455336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BaseEncoder(nn.Module):\n    \"\"\"\n    A flexible encoder model that supports different architectures (ResNet, EfficientNet, etc.).\n    \"\"\"\n\n    def __init__(self, arch=\"resnet18\", pretrained=True, no_channels=3, dropout=0.5, add_block=False, num_frozen=0):\n        super(BaseEncoder, self).__init__()\n\n        self.add_block = add_block\n        self.num_frozen = num_frozen\n\n        # Dictionary of available architectures\n        arch_dict = {\n            \"resnet18\": models.resnet18,\n            \"resnet50\": models.resnet50,\n            \"resnet101\": models.resnet101,\n            \"efficientnet_b0\": models.efficientnet_b0,\n            \"efficientnet_b4\": models.efficientnet_b4,\n        }\n\n        assert arch in arch_dict, f\"Unsupported architecture: {arch}. Choose from {list(arch_dict.keys())}\"\n\n        # Load the model\n        self.model = arch_dict[arch](weights=\"DEFAULT\" if pretrained else None)\n\n        if \"resnet\" in arch:\n            self.feature_dim = self.model.fc.in_features\n            self.model.fc = nn.Identity()  \n        elif \"efficientnet\" in arch:\n            self.feature_dim = self.model.classifier[1].in_features\n            self.model.classifier = nn.Identity() \n\n        if no_channels != 3:\n            if \"resnet\" in arch:\n                self.model.conv1 = nn.Conv2d(no_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            elif \"efficientnet\" in arch:\n                self.model.features[0][0] = nn.Conv2d(no_channels, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n\n        if self.add_block:\n            self.addition_block = nn.Sequential(\n                nn.Linear(self.feature_dim, self.feature_dim),\n                nn.BatchNorm1d(self.feature_dim),\n                nn.Dropout(dropout),\n                nn.Linear(self.feature_dim, self.feature_dim)\n            )\n\n        self.final_layers = nn.Sequential(\n            nn.Linear(self.feature_dim, 512),\n            nn.BatchNorm1d(512),\n            nn.Dropout(dropout),\n            nn.Linear(512, 512)\n        )\n\n        self.freeze_layers()\n\n    def freeze_layers(self):\n        \"\"\"\n        Freeze the first `num_frozen` layers of the model.\n        \"\"\"\n        layers = list(self.model.children())\n        assert 0 <= self.num_frozen <= len(layers), \\\n            f\"num_frozen should be between 0 and {len(layers)}\"\n\n        for i, child in enumerate(layers):\n            if i < self.num_frozen:\n                for param in child.parameters():\n                    param.requires_grad = False\n\n        print(f\"Number of frozen layers: {self.num_frozen}\")\n\n    def forward(self, x):\n        x = self.model(x)\n        if self.add_block:\n            x = self.addition_block(x)\n        x = self.final_layers(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.456985Z","iopub.execute_input":"2025-02-08T15:52:26.457212Z","iopub.status.idle":"2025-02-08T15:52:26.471671Z","shell.execute_reply.started":"2025-02-08T15:52:26.457195Z","shell.execute_reply":"2025-02-08T15:52:26.470973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AQIPrediction(nn.Module):\n    \"\"\"\n    Unified model\n    \"\"\"\n    \n    def __init__(self, satellite_model, street_model, dropout=0.5, num_classes=None):\n        \n        super(AQIPrediction, self).__init__()\n        \n        self.satellite_model = satellite_model\n        self.street_model = street_model\n        \n        self.final_layers = nn.Sequential(\n            nn.Linear(512 + 512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(512, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 1)\n        )\n        if num_classes:\n            self.final_layers[-1] = nn.Linear(128, num_classes)\n            \n    def forward(self, street_img, satellite_img):\n        \n        street_features = self.street_model(street_img)\n        satellite_features = self.satellite_model(satellite_img)\n        \n        features = torch.cat((street_features, satellite_features), dim=1)\n        output = self.final_layers(features)\n        \n        return output\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.472308Z","iopub.execute_input":"2025-02-08T15:52:26.472517Z","iopub.status.idle":"2025-02-08T15:52:26.488590Z","shell.execute_reply.started":"2025-02-08T15:52:26.472488Z","shell.execute_reply":"2025-02-08T15:52:26.487751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\nsatellite_encoder = BaseEncoder(arch='resnet18', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\nstreet_encoder = BaseEncoder(arch='resnet18', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n\nmodel = AQIPrediction(satellite_encoder, street_encoder, dropout=0.5, num_classes=None)\n\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n\nhistory = train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, EPOCHS, 'resnet18_best_model.pth')\n\nplot_metrics(**history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.489385Z","iopub.execute_input":"2025-02-08T15:52:26.489644Z","iopub.status.idle":"2025-02-08T15:52:26.503110Z","shell.execute_reply.started":"2025-02-08T15:52:26.489619Z","shell.execute_reply":"2025-02-08T15:52:26.502355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\nsatellite_encoder = BaseEncoder(arch='resnet50', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\nstreet_encoder = BaseEncoder(arch='resnet50', no_channels=3, dropout=0.5, add_block=EXTRA_LAYER, num_frozen=NUM_FROZEN_LAYERS)\n\nmodel = AQIPrediction(satellite_encoder, street_encoder, dropout=0.5, num_classes=None)\n\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n\nhistory = train(model, optimizer, scheduler, train_loader, val_loader, test_loader, device, EPOCHS, 'resnet50_best_model.pth')\n\nplot_metrics(**history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T15:52:26.503822Z","iopub.execute_input":"2025-02-08T15:52:26.504237Z","execution_failed":"2025-02-08T15:52:49.960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}